{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation test using dilated convolutional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name of corpus file (without txt extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpusname = \"lapeceramicro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of past input tokens to use for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputtokens = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network architecture to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "architecture = \"dilatedconv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all relevant file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpusfile = 'corpus/' + corpusname + '.txt'\n",
    "encodername = corpusname + '.enc'\n",
    "modelname = corpusname + '.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from neurowriter.models import modelbyname\n",
    "modelclass = modelbyname(architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(corpusfile) as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2/11/2014, 11:54 - Sergio Nabil Khayyat cre√≥ el grupo ‚ÄúLa pecera‚Äù\\n2/11/2014, 11:55 - Sergio Nabil Khayyat te a√±adi√≥\\n2/11/2014, 11:54 - Sergio Nabil Khayyat cambi√≥ el icono de este grupo\\n2/11/2014, 12:04 - Carmen Torrijos cambi√≥ el asunto a ‚ÄúLa pecera \\ue522‚Äù\\n2/11/2014, 12:06 - √Ålvaro Barbero Jim√©nez: Ola k aseis\\n2/11/2014, 12:07 - √Ålvaro Barbero Jim√©nez: Bamonos dE peshka\\n2/11/2014, 12:07 - √Ålvaro Barbero Jim√©nez: Al bershka\\n2/11/2014, 12:07 - Carmen Torrijos: Buena inauguracion del grupo jajaj \\ue00e\\n2/11/2014, 23:33 - Jorge L√≥pez L√°zaro: Capitalism Explained. This Is So Accurate It Hurts. - http://m.tickld.com/x/capitalism-explained-this-is-so-accurate-it-hurts\\n3/11/2014, 0:37 - Alicia Gonz√°lez: \\ue412\\n3/11/2014, 10:06 - Sergio Nabil Khayyat a√±adi√≥ a David D√≠az Vico\\n4/11/2014, 8:34 - Carmen Torrijos: Pastas en el office! üç•üç•\\n4/11/2014, 8:45 - Alicia Gonz√°lez: llego mazo tarde \\ue058\\n4/11/2014, 8:46 - Carmen Torrijos: \\ue115\\ue230\\n4/11/2014, 11:47 - Sergio Nabil Khayyat a√±adi√≥ a Adri√°n Ram√≠rez\\n10/11/2014, 19:08 - S'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:min(1000,len(corpus))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder lapeceramicro.enc\n"
     ]
    }
   ],
   "source": [
    "from neurowriter.encoding import Encoder, loadencoding\n",
    "try:\n",
    "    encoder = loadencoding(encodername)\n",
    "    print(\"Loaded encoder\", encodername)\n",
    "except Exception as e:\n",
    "    print(\"Encoder not found, creating new encoder:\", e)\n",
    "    encoder = Encoder(corpus)\n",
    "    encoder.save(encodername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: [4, 32, 0.60276337607164387, 2, 64, 0.64589411306665612, 'rmsprop'] , loss:  3.60489155451\n",
      "Params: [5, 64, 0.38344151882577771, 3, 64, 0.56804456109393231, 'adam'] , loss:  3.58911536535\n",
      "Params: [2, 4, 0.020218397440325719, 3, 128, 0.87001214824681916, 'adam'] , loss:  3.59204134941\n",
      "Params: [5, 16, 0.78052917628645546, 0, 128, 0.1433532874090464, 'adam'] , loss:  3.73669484456\n",
      "Params: [4, 16, 0.26455561210462697, 3, 64, 0.56843394886864851, 'sgd'] , loss:  3.61186521848\n",
      "Params: [4, 32, 0.61693399687475692, 3, 128, 0.35950790057378601, 'rmsprop'] , loss:  3.61531596184\n",
      "Params: [4, 4, 0.66676671544566768, 2, 32, 0.12892629765485331, 'sgd'] , loss:  3.65036411285\n",
      "Params: [3, 16, 0.43860151346232035, 3, 16, 0.20887675609483469, 'sgd'] , loss:  3.60718886058\n",
      "Params: [4, 8, 0.46631077285630629, 0, 16, 0.11037514116430513, 'rmsprop'] , loss:  3.74341654778\n",
      "Params: [2, 4, 0.36872517066096411, 3, 16, 0.8379449074988039, 'sgd'] , loss:  3.65118765831\n",
      "Params: [4, 64, 0.53074244144301741, 0, 32, 0.94464583293634086, 'rmsprop'] , loss:  3.19233778318\n",
      "Params: [2, 64, 0.77955082506835049, 3, 64, 0.96309199620275521, 'rmsprop'] , loss:  3.59246122042\n",
      "Params: [5, 64, 0.072577230789806602, 1, 32, 0.94568820836463585, 'rmsprop'] , loss:  3.60532447497\n",
      "Params: [2, 64, 0.79835378623829534, 0, 32, 0.71965786019848654, 'sgd'] , loss:  3.79235548973\n",
      "Params: [4, 64, 0.31176238639079479, 1, 32, 0.93707285364491244, 'rmsprop'] , loss:  3.60400276184\n",
      "Params: [4, 64, 0.48306192482051535, 1, 32, 0.94403814350671722, 'rmsprop'] , loss:  3.6058022817\n",
      "Params: [4, 8, 0.78599524691741041, 1, 256, 0.94457584587773813, 'sgd'] , loss:  3.6264113903\n",
      "Params: [4, 64, 0.54552599161559201, 0, 128, 0.96223676057858398, 'rmsprop'] , loss:  3.19415775935\n",
      "Params: [4, 64, 0.5349080534274917, 0, 256, 0.97041124207670926, 'rmsprop'] , loss:  3.21643865903\n",
      "Params: [4, 4, 0.54464226309475139, 0, 32, 0.98915477897325255, 'sgd'] , loss:  3.70475854874\n",
      "Params: [4, 32, 0.50962369341239733, 0, 64, 0.97399184514545878, 'adam'] , loss:  3.10932882627\n",
      "Params: [4, 16, 0.51931454225047913, 0, 16, 0.98770852315483837, 'sgd'] , loss:  3.72991148631\n",
      "Params: [3, 64, 0.11332591350437038, 0, 256, 0.97208125856119254, 'adam'] , loss:  2.91785527865\n",
      "Params: [3, 64, 0.5858744185565441, 0, 256, 0.97273533727141448, 'adam'] , loss:  2.81940960884\n",
      "Params: [3, 16, 0.5731333915693968, 0, 64, 0.99798016213841856, 'adam'] , loss:  2.99940066338\n",
      "Params: [3, 4, 0.70993047942291754, 0, 256, 0.97840236551895232, 'adam'] , loss:  3.62989004453\n",
      "Params: [3, 8, 0.31415612079925992, 0, 64, 0.98551292604024987, 'adam'] , loss:  3.04699713389\n",
      "Params: [3, 64, 0.43779224649845294, 0, 16, 0.97186138776130226, 'adam'] , loss:  2.73048048019\n",
      "Params: [3, 64, 0.26851135315486219, 0, 16, 0.96684593197890201, 'adam'] , loss:  2.80014333725\n",
      "Params: [3, 64, 0.58174981067132137, 0, 16, 0.97101445651032214, 'adam'] , loss:  2.82030480703\n",
      "Params: [3, 64, 0.31105787073272984, 0, 16, 0.95245886683416447, 'adam'] , loss:  3.12627294858\n",
      "Params: [3, 64, 0.55427959070264399, 0, 64, 0.99833969972327774, 'rmsprop'] , loss:  2.97878216108\n",
      "Params: [3, 64, 0.22481704567227412, 0, 128, 0.98667380395876592, 'adam'] , loss:  2.74786520004\n",
      "Params: [3, 64, 0.20815492522892232, 0, 64, 0.98418020710907228, 'adam'] , loss:  2.7282298406\n",
      "Params: [3, 64, 0.58943624946822515, 0, 16, 0.99629113858366214, 'adam'] , loss:  2.75746572812\n",
      "Params: [3, 64, 0.18200909508211061, 0, 64, 0.9907099372317526, 'rmsprop'] , loss:  2.90284053485\n",
      "Params: [3, 32, 0.065110872485592219, 0, 128, 0.98653659790111403, 'adam'] , loss:  3.08299314181\n",
      "Params: [3, 64, 0.17234721373492345, 0, 64, 0.98902179176810412, 'sgd'] , loss:  3.61180165609\n",
      "Params: [3, 64, 0.55575081088321998, 0, 16, 0.97736717649136917, 'adam'] , loss:  2.77138420741\n",
      "Params: [3, 64, 0.48667344988777417, 1, 32, 0.98711332113643624, 'adam'] , loss:  3.59805841446\n",
      "Params: [3, 64, 0.57832127167170533, 0, 256, 0.99240730180907955, 'rmsprop'] , loss:  3.04233023326\n",
      "Params: [3, 64, 0.28370368861895245, 0, 256, 0.95873635118996092, 'adam'] , loss:  2.68538120588\n",
      "Params: [3, 64, 0.24962025681661704, 0, 64, 0.96076932024810147, 'adam'] , loss:  2.78733695348\n",
      "Params: [3, 64, 0.29244525700879231, 0, 256, 0.97531853309484784, 'rmsprop'] , loss:  3.20238898595\n",
      "Params: [3, 64, 0.017338862804573862, 0, 32, 0.99010231977223373, 'adam'] , loss:  2.95772145589\n",
      "Params: [3, 64, 0.75933367353235248, 0, 16, 0.99695390845299459, 'adam'] , loss:  2.94215327899\n",
      "Params: [3, 64, 0.20214639641898458, 0, 32, 0.96249880700229862, 'adam'] , loss:  2.90113010406\n",
      "Params: [3, 64, 0.89196472103426849, 0, 256, 0.55029856414880141, 'adam'] , loss:  3.17824831009\n",
      "Params: [3, 64, 0.25384556130875613, 0, 64, 0.97282839601960858, 'adam'] , loss:  2.79973864555\n",
      "Params: [3, 64, 0.36858677532312711, 0, 256, 0.9960938540358879, 'adam'] , loss:  2.7469458739\n",
      "Params: [3, 64, 0.19315814648337259, 0, 256, 0.95824000997978598, 'adam'] , loss:  2.84383633931\n",
      "Params: [3, 64, 0.86155135897082291, 0, 128, 0.99865752736998481, 'adam'] , loss:  3.11487857501\n",
      "Params: [3, 64, 0.58058856354323829, 0, 16, 0.97229208484202123, 'adam'] , loss:  2.79367380142\n",
      "Params: [3, 64, 0.78329089892968284, 0, 256, 0.97036272180275729, 'adam'] , loss:  2.96440585454\n",
      "Params: [3, 64, 0.47322542508322518, 0, 128, 0.96993832162798355, 'adam'] , loss:  2.70312989553\n",
      "Params: [3, 64, 0.22540996103422495, 0, 128, 0.96839196700131913, 'adam'] , loss:  2.82695403099\n",
      "Params: [3, 64, 0.20764251112043119, 0, 16, 0.99511673412862944, 'adam'] , loss:  2.9018043677\n",
      "Params: [3, 64, 0.41371339999208112, 0, 32, 0.95653450050472, 'adam'] , loss:  2.7510855039\n",
      "Params: [3, 64, 0.3061787840277046, 0, 64, 0.97468673166886521, 'adam'] , loss:  2.71016265551\n",
      "Params: [3, 64, 0.2632452965657035, 0, 32, 0.96046114627329138, 'adam'] , loss:  2.8022195816\n",
      "Params: [3, 64, 0.30574134742788672, 1, 128, 0.99870694728980047, 'adam'] , loss:  3.59094470342\n",
      "Params: [3, 64, 0.23991618811649007, 0, 16, 0.14451124509515811, 'adam'] , loss:  2.82018624942\n",
      "Params: [3, 64, 0.54891702213842242, 0, 256, 0.033215165777106814, 'adam'] , loss:  2.89974433581\n",
      "Params: [3, 64, 0.34312532042065946, 0, 128, 0.02524775918519051, 'adam'] , loss:  2.68977429072\n",
      "Params: [3, 4, 0.10473011784168096, 0, 64, 0.023163845775099001, 'adam'] , loss:  3.01557672819\n",
      "Params: [3, 64, 0.34757433200462717, 0, 256, 0.020110227413632331, 'adam'] , loss:  2.69814283053\n",
      "Params: [3, 64, 0.37202926057015473, 0, 16, 0.98187694862356523, 'adam'] , loss:  2.79096271197\n",
      "Params: [3, 64, 0.24355371925586533, 0, 64, 0.98347878319457727, 'adam'] , loss:  3.14386305809\n",
      "Params: [3, 64, 0.45541623526890684, 0, 128, 0.95297820432513247, 'adam'] , loss:  2.76419919332\n",
      "Params: [3, 64, 0.28545478782919564, 0, 128, 0.92204816456787153, 'adam'] , loss:  2.78987437884\n",
      "Params: [3, 64, 0.47730640743157204, 0, 32, 0.71655922214854317, 'adam'] , loss:  2.8202633063\n",
      "Params: [5, 64, 0.59272296288068993, 0, 128, 0.024440904319365409, 'adam'] , loss:  3.44513351123\n",
      "Params: [3, 4, 0.23971758343777594, 0, 128, 0.0043263983672495732, 'adam'] , loss:  3.26179119746\n",
      "Params: [3, 64, 0.42614051796123498, 0, 16, 0.017070724654575931, 'adam'] , loss:  3.20909964244\n",
      "Params: [3, 64, 0.33470533948350012, 0, 64, 0.80773877467486921, 'adam'] , loss:  2.75948052406\n",
      "Params: [3, 64, 0.40706552477606273, 0, 32, 0.726400030623231, 'adam'] , loss:  2.73559672038\n",
      "Params: [3, 64, 0.34514065336837108, 0, 16, 0.84321406321957859, 'adam'] , loss:  2.67198081017\n"
     ]
    }
   ],
   "source": [
    "from neurowriter.optimizer import hypertrain\n",
    "\n",
    "model, train_history = hypertrain(modelclass, inputtokens, encoder, corpus, n_calls=100)\n",
    "model.save(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neurowriter.writer import Writer\n",
    "\n",
    "writer = Writer(model, encoder, creativity=0.1)\n",
    "print(corpus[:inputtokens])\n",
    "''.join(writer.write(seed=corpus[:inputtokens]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Manual test generation test with 0 creativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = corpus[:inputtokens]\n",
    "print(\"Seed:\", seed)\n",
    "print(\"Generated\")\n",
    "print(seed, end='')\n",
    "for i in range(1000):\n",
    "    seedcoded = encoder.encodetext(seed)\n",
    "    #cls = model.predict_classes(np.array([seedcoded]), verbose=0)\n",
    "    #char = encoder.index2char[cls[0]]\n",
    "    cls = np.argmax(model.predict(np.array([seedcoded])))\n",
    "    char = encoder.index2char[cls]\n",
    "    print(char, end='')\n",
    "    seed = seed[1:] + char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Possible improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try training with SGD and the full pecera corpus for a large number of iterations\n",
    "* Add more residual blocks\n",
    "\n",
    "From Facebook's convolutional translation paper\n",
    "* Tokens are dealt with embeddings instead of one-hot encoder.\n",
    "* The position of each token is also added as a parallel embedding\n",
    "* Dropout for the embeddings and for the input of each convolutional block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* WaveNet paper: https://arxiv.org/pdf/1609.03499.pdf\n",
    "* A Keras implementation of WaveNet: https://github.com/usernaamee/keras-wavenet/blob/master/simple-generative-model.py\n",
    "* Another one: https://github.com/basveeling/wavenet/blob/master/wavenet.py\n",
    "* Facebook's convolutional translation paper: https://arxiv.org/pdf/1705.03122.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scrapyard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def sampletext(logs):\n",
    "    \"\"\"Function that generates some sample text with the model.\n",
    "\n",
    "    Intented to be used as a keras callback\n",
    "    \"\"\"\n",
    "    writer = Writer(model, encoder, creativity=0.1)\n",
    "    print(corpus[:inputtokens])\n",
    "    print(''.join(writer.write(seed=corpus[:inputtokens])))\n",
    "\n",
    "# Build model with input parameters\n",
    "model = modelkind(inputtokens, encoder, *bestparams)\n",
    "# Prepare callbacks\n",
    "callbacks = [\n",
    "    LambdaCallback(on_train_end=sampletext),\n",
    "    ModelCheckpoint(filepath=modelname,save_best_only=True),\n",
    "    EarlyStopping(patience=patience)\n",
    "]\n",
    "# Train model\n",
    "model.fit_generator(\n",
    "    traingenerator,\n",
    "    steps_per_epoch=int((1-val)*(len(corpus)-inputtokens+1)/batchsize),\n",
    "    validation_data=valgenerator,\n",
    "    validation_steps=int(val*(len(corpus)-inputtokens+1)/batchsize),\n",
    "    epochs=maxepochs,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
